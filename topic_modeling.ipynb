{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuP/9Ca9nXpmLPih0eJcW5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# topic modeling\n",
        "LDA(latent dirichlet allocation)\n",
        "\n",
        "NMF(non negative matrix factorization)"
      ],
      "metadata": {
        "id": "fNI1_fuYrhjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "bUwClvyS0XpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiDAF8U-iw9p",
        "outputId": "869f2df4-b9cc-40a4-c412-b44d5cd65a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documnets=[\n",
        "    \"machine learning is amazing for predictive analysis.\",\n",
        "    \"deep learning and neural network are a subset of machine learning.\",\n",
        "    \"natural language processing is a part of ai.\",\n",
        "    \"ai includes vision,robotics,and natural understanding.\",\n",
        "   \"generative ai like chatgpt creates human like text.\",\n",
        "]"
      ],
      "metadata": {
        "id": "KGLsaJbRixA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "stop_words=set(stopwords.words('english'))\n",
        "processed_doc=[\n",
        "    [word.lower() for word in word_tokenize(doc) if word.isalnum() and word.lower() not in stop_words]\n",
        "    for doc in documnets\n",
        "]"
      ],
      "metadata": {
        "id": "TYl513ezixEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuxB-xR2ixHP",
        "outputId": "13831c66-aed2-494c-f3f0-93dec4e59d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['machine', 'learning', 'amazing', 'predictive', 'analysis'],\n",
              " ['deep', 'learning', 'neural', 'network', 'subset', 'machine', 'learning'],\n",
              " ['natural', 'language', 'processing', 'part', 'ai'],\n",
              " ['ai', 'includes', 'vision', 'robotics', 'natural', 'understanding'],\n",
              " ['generative', 'ai', 'like', 'chatgpt', 'creates', 'human', 'like', 'text']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dictionary and corpus\n",
        "dictionary=Dictionary(processed_doc) # converts each of words and unique integer IDs.\n",
        "corpus=[dictionary.doc2bow(doc) for doc in processed_doc]"
      ],
      "metadata": {
        "id": "XFbcVkxEv3DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mkc6CcOv3Fz",
        "outputId": "a3ff6ae7-ac7a-4646-a40d-be3cf28e4a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x7f1c9fbbacd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu5VGdLHwZiI",
        "outputId": "9982504a-ea93-4447-ae76-7ecdd1200b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
              " [(2, 2), (3, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
              " [(9, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
              " [(9, 1), (11, 1), (14, 1), (15, 1), (16, 1), (17, 1)],\n",
              " [(9, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA model\n",
        "lda_model=LdaModel(corpus=corpus,id2word=dictionary,num_topics=3,passes=10)"
      ],
      "metadata": {
        "id": "SmCVT5KSwZky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display topics\n",
        "topics=lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(f'Topic {topics.index(topic)}: {topic}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tktFv9ntwZny",
        "outputId": "f41c74e6-936d-40ac-ef77-d592bc654404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: (0, '0.123*\"natural\" + 0.123*\"ai\" + 0.070*\"processing\" + 0.070*\"language\" + 0.070*\"includes\"')\n",
            "Topic 1: (1, '0.166*\"learning\" + 0.117*\"machine\" + 0.067*\"amazing\" + 0.067*\"analysis\" + 0.067*\"predictive\"')\n",
            "Topic 2: (2, '0.145*\"like\" + 0.084*\"ai\" + 0.083*\"generative\" + 0.083*\"chatgpt\" + 0.083*\"text\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF"
      ],
      "metadata": {
        "id": "KcU6PvRM0TXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nmf topic modeling with scikit learn\n",
        "\n",
        "nmf non negative matrix factorization\n",
        "\n",
        "# key features\n",
        "non negative constraint\n",
        "\n",
        "factorization\n",
        "\n",
        "objective function"
      ],
      "metadata": {
        "id": "jAyT_1UK4sBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF"
      ],
      "metadata": {
        "id": "iWZTKbwiyi0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documnets=[\n",
        "    \"machine learning is amazing for predictive analysis.\",\n",
        "    \"deep learning and neural network are a subset of machine learning.\",\n",
        "    \"natural language processing is a part of ai.\",\n",
        "    \"ai includes vision,robotics,and natural understanding.\",\n",
        "   \"generative ai like chatgpt creates human like text.\",\n",
        "]"
      ],
      "metadata": {
        "id": "uQdxD0l32DcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf-tdf vectorization\n",
        "vectorizer=TfidfVectorizer(max_df=0.95,min_df=2,stop_words='english')\n",
        "tfidf_matrix=vectorizer.fit_transform(documnets)"
      ],
      "metadata": {
        "id": "PsQ3P9th2Dfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nmf model\n",
        "nmf_model=NMF(n_components=3,random_state=42)\n",
        "w=nmf_model.fit(tfidf_matrix)\n",
        "h=nmf_model.components_\n",
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geFxrmeJ5_QG",
        "outputId": "df0f76de-54c2-4104-d3ed-a3e9a1f6edf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.22800047, 0.        , 0.        , 2.6085111 ],\n",
              "       [0.        , 1.4518495 , 1.04643391, 0.        ],\n",
              "       [0.92880534, 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display topics\n",
        "feature_names=vectorizer.get_feature_names_out()\n",
        "for topic_idx,topic in enumerate(h):\n",
        "    print(f\"topic {topic_idx}:{''.join([feature_names[i] for i in topic.argsort()[-5:]])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dX-foFA5_S7",
        "outputId": "ab83d407-d54d-4cfa-ec67-dec5b8ce9125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0:learningmachineainatural\n",
            "topic 1:ainaturalmachinelearning\n",
            "topic 2:learningmachinenaturalai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHxCPg1Oyi3Y",
        "outputId": "8b0c3d33-89bd-4b74-d4b8-ea2527f8afa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ai', 'learning', 'machine', 'natural'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgwPY6Tn7xvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FR-BkvqJ5mhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}